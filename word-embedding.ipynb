{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Giá»›i thiá»‡u"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Word2vec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1. Giá»›i thiá»‡u\n",
    "\n",
    "Word2vec lÃ  má»™t ká»¹ thuáº­t Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Tomas Mikolov vÃ o nÄƒm 2013 Ä‘á»ƒ há»c word embeddings tá»« má»™t lÆ°á»£ng lá»›n dá»¯ liá»‡u vÄƒn báº£n. Word2vec khÃ´ng cáº§n dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c gáº¯n nhÃ£n (nhÆ° phÃ¢n loáº¡i tá»«); thay vÃ o Ä‘Ã³, nÃ³ sá»­ dá»¥ng self-supervised learning, nghÄ©a lÃ  nÃ³ tá»± há»c tá»« chÃ­nh dá»¯ liá»‡u báº±ng cÃ¡ch dá»± Ä‘oÃ¡n má»™t pháº§n dá»¯ liá»‡u dá»±a trÃªn pháº§n khÃ¡c.\n",
    "\n",
    "Word2vec cÃ³ hai mÃ´ hÃ¬nh chÃ­nh:\n",
    "- **Skip-gram**: Skip-gram dá»± Ä‘oÃ¡n cÃ¡c tá»« ngá»¯ cáº£nh dá»±a trÃªn tá»« má»¥c tiÃªu. Vá»›i tá»« \"sits\", mÃ´ hÃ¬nh cá»‘ gáº¯ng dá»± Ä‘oÃ¡n cÃ¡c tá»« nhÆ° \"the\", \"cat\", \"on\", \"the\", \"mat\".\n",
    "- **Continuous Bag of Words (CBOW)**: NgÆ°á»£c láº¡i vá»›i Skip-gram, dá»± Ä‘oÃ¡n má»™t tá»« má»¥c tiÃªu dá»±a trÃªn cÃ¡c tá»« ngá»¯ cáº£nh xung quanh nÃ³. VÃ­ dá»¥, vá»›i cÃ¢u \"the cat sits on the mat\", CBOW láº¥y cÃ¡c tá»« \"the\", \"cat\", \"on\", \"the\", \"mat\" Ä‘á»ƒ dá»± Ä‘oÃ¡n tá»« \"sits\".\n",
    "\n",
    "DÆ°á»›i Ä‘Ã¢y lÃ  báº£ng so sÃ¡nh nhanh giá»¯a hai mÃ´ hÃ¬nh:\n",
    "\n",
    "|MÃ´ hÃ¬nh |\tMá»¥c tiÃªu |\tVÃ­ dá»¥|\n",
    "|--------|-----------|-------|\n",
    "|Skip-gram|\tDá»± Ä‘oÃ¡n context tá»« center word|\tTá»« \"Äƒn\" dá»± Ä‘oÃ¡n \"tÃ´i\" vÃ  \"tÃ¡o\".|\n",
    "|Continuous Bag of Words (CBOW)|\tDá»± Ä‘oÃ¡n center word tá»« context|\tTá»« \"tÃ´i\" vÃ  \"tÃ¡o\" dá»± Ä‘oÃ¡n \"Äƒn\".|\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <div style=\"display: inline-block;\">\n",
    "        <p style=\"font-style: italic; color: gray; text-align: center; margin: 4px 0 0 0;\">Báº£ng 1: So sÃ¡nh Skip-gram vÃ  CBOW.</p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <div style=\"display: inline-block;\">\n",
    "        <img src=\"https://github.com/hcmut-aa-math/word-embedding/blob/master/assets/pic3-cbow-and-skipgram.png?raw=true\" style=\"width: 600px; height: auto;\" />\n",
    "        <p style=\"font-style: italic; color: gray; text-align: center; margin: 4px 0 0 0;\">\n",
    "            HÃ¬nh 3: Kiáº¿n trÃºc CBOW dá»± Ä‘oÃ¡n tá»« hiá»‡n táº¡i dá»±a trÃªn ngá»¯ cáº£nh, cÃ²n Skip-gram dá»± Ä‘oÃ¡n cÃ¡c tá»« xung quanh dá»±a vÃ o tá»« hiá»‡n táº¡i.\n",
    "        </p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "Cáº£ hai mÃ´ hÃ¬nh Ä‘á»u dá»±a trÃªn cÃ¡c cÃ´ng thá»©c toÃ¡n há»c Ä‘á»ƒ tÃ­nh xÃ¡c suáº¥t Ä‘iá»u kiá»‡n, sá»­ dá»¥ng hÃ m softmax vÃ  dot product giá»¯a cÃ¡c vector tá»«. DÆ°á»›i Ä‘Ã¢y lÃ  phÃ¢n tÃ­ch chi tiáº¿t tá»«ng cÃ´ng thá»©c."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2. Skip-gram\n",
    "### 2.2.1 Äá»‹nh nghÄ©a\n",
    "MÃ´ hÃ¬nh skip-gam giáº£ Ä‘á»‹nh ráº±ng má»™t tá»« cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ sinh ra cÃ¡c tá»« xung quanh nÃ³ trong má»™t chuá»—i vÄƒn báº£n. VÃ­ dá»¥, giáº£ sá»­ chuá»—i vÄƒn báº£n lÃ  â€œtheâ€, â€œmanâ€, â€œlovesâ€, â€œhisâ€ vÃ  â€œsonâ€. Ta sá»­ dá»¥ng â€œlovesâ€ lÃ m tá»« Ä‘Ã­ch trung tÃ¢m vÃ  Ä‘áº·t kÃ­ch thÆ°á»›c cá»­a sá»• ngá»¯ cáº£nh báº±ng 2. NhÆ° mÃ´ táº£ trong HÃ¬nh 2, vá»›i tá»« Ä‘Ã­ch trung tÃ¢m â€œlovesâ€, mÃ´ hÃ¬nh skip-gram quan tÃ¢m Ä‘áº¿n xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n sinh ra cÃ¡c tá»« ngá»¯ cáº£nh (â€œtheâ€, â€œmanâ€, â€œhisâ€ vÃ  â€œsonâ€) náº±m trong khoáº£ng cÃ¡ch khÃ´ng quÃ¡ 2 tá»«:\n",
    "\n",
    "$$\n",
    "P(\\textrm{\"the\"},\\textrm{\"man\"},\\textrm{\"his\"},\\textrm{\"son\"}\\mid\\textrm{\"loves\"}).\n",
    "$$\n",
    "\n",
    "Ta giáº£ Ä‘á»‹nh ráº±ng, vá»›i tá»« Ä‘Ã­ch trung tÃ¢m cho trÆ°á»›c, cÃ¡c tá»« ngá»¯ cáº£nh Ä‘Æ°á»£c sinh ra Ä‘á»™c láº­p vá»›i nhau. Trong trÆ°á»ng há»£p nÃ y, cÃ´ng thá»©c trÃªn cÃ³ thá»ƒ Ä‘Æ°á»£c viáº¿t láº¡i thÃ nh\n",
    "\n",
    "$$\n",
    "P(\\textrm{\"the\"}\\mid\\textrm{\"loves\"})\\cdot P(\\textrm{\"man\"}\\mid\\textrm{\"loves\"})\\cdot P(\\textrm{\"his\"}\\mid\\textrm{\"loves\"})\\cdot P(\\textrm{\"son\"}\\mid\\textrm{\"loves\"}).\n",
    "$$\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <div style=\"display: inline-block;\">\n",
    "        <img src=\"https://github.com/hcmut-aa-math/word-embedding/blob/master/assets/pic4-skipgram.png?raw=true\" style=\"width: 600px; height: auto;\" />\n",
    "        <p style=\"font-style: italic; color: gray; text-align: center; margin: 4px 0 0 0;\">\n",
    "            HÃ¬nh 4: MÃ´ hÃ¬nh skip-gram quan tÃ¢m Ä‘áº¿n xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n sinh ra cÃ¡c tá»« ngá»¯ cáº£nh vá»›i má»™t tá»« Ä‘Ã­ch trung tÃ¢m cho trÆ°á»›c..\n",
    "        </p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "Trong mÃ´ hÃ¬nh skip-gam, má»—i tá»« Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng hai vector $d-\\text{chiá»u}$ (má»™t dÃ¹ng khi tá»« $w$ lÃ  tá»« ngá»¯ cáº£nh, má»™t dÃ¹ng khi tá»« $w$ lÃ  tá»« trung tÃ¢m) Ä‘á»ƒ tÃ­nh xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n. Giáº£ sá»­ chá»‰ sá»‘ cá»§a má»™t tá»« trong tá»« Ä‘iá»ƒn lÃ  $i$, vector cá»§a tá»« Ä‘Æ°á»£c biá»ƒu diá»…n lÃ  $\\mathbf{v}_i\\in\\mathbb{R}^d$ khi tá»« nÃ y lÃ  tá»« Ä‘Ã­ch trung tÃ¢m vÃ  lÃ  $\\mathbf{u}_i\\in\\mathbb{R}^d$ khi tá»« nÃ y lÃ  má»™t tá»« ngá»¯ cáº£nh. Gá»i $c$ vÃ  $o$ láº§n lÆ°á»£t lÃ  chá»‰ sá»‘ cá»§a tá»« Ä‘Ã­ch trung tÃ¢m $w_c$ vÃ  tá»« ngá»¯ cáº£nh $w_o$ trong tá»« Ä‘iá»ƒn. CÃ³ thá»ƒ thu Ä‘Æ°á»£c xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n sinh ra tá»« ngá»¯ cáº£nh cho má»™t tá»« Ä‘Ã­ch trung tÃ¢m cho trÆ°á»›c báº±ng phÃ©p toÃ¡n softmax trÃªn tÃ­ch vÃ´ hÆ°á»›ng cá»§a vector:\n",
    "\n",
    "$$\n",
    "P(w_o \\mid w_c) = \\frac{\\exp(\\mathbf{u}_o^\\top \\mathbf{v}_c)}{ \\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)},\n",
    "$$\n",
    "\n",
    "Trong Ä‘Ã³:\n",
    "- $w_c$: Tá»« trung tÃ¢m (center word), vÃ­ dá»¥ \"cat\" trong cÃ¢u \"the cat sat on mat\".\n",
    "- $w_o$: Tá»« ngá»¯ cáº£nh (output word), vÃ­ dá»¥ \"sat\" trong cÃ¹ng cÃ¢u.\n",
    "- $\\mathbf{v}_c \\in \\mathbb{R}^d$: Vector biá»ƒu diá»…n cá»§a tá»« trung tÃ¢m $w_c$ (input vector).\n",
    "- $\\mathbf{u}_o \\in \\mathbb{R}^d$: Vector biá»ƒu diá»…n cá»§a tá»« ngá»¯ cáº£nh $w_o$ (output vector).\n",
    "- $\\mathcal{V}$: Táº­p há»£p táº¥t cáº£ tá»« trong tá»« Ä‘iá»ƒn (vocabulary). Táº­p chá»‰ sá»‘ trong bá»™ tá»« vá»±ng lÃ  $\\mathcal{V} = \\{0, 1, \\ldots, |\\mathcal{V}|-1\\}$.\n",
    "- $\\mathbf{u}_i \\in \\mathbb{R}^d$: Vector biá»ƒu diá»…n cá»§a tá»« $i$ trong tá»« Ä‘iá»ƒn.\n",
    "- $\\exp$: HÃ m mÅ©, $\\exp(x) = e^x$\n",
    "- $\\mathbf{u}_o^\\top \\mathbf{v}_c$: TÃ­ch vÃ´ hÆ°á»›ng (dot product) giá»¯a vector $\\mathbf{u}_o$ vÃ  $\\mathbf{v}_c$, Ä‘o lÆ°á»ng má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a tá»« trung tÃ¢m vÃ  tá»« ngá»¯ cáº£nh.\n",
    "- $\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)$: Tá»•ng chuáº©n hÃ³a (normalization term) giá»¯a cÃ¡c Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng mÅ© giá»¯a tá»« trung tÃ¢m $w_c$ trÃªn toÃ n bá»™ tá»« Ä‘iá»ƒn $\\mathcal{V}$, Ä‘áº£m báº£o cÃ¡c xÃ¡c suáº¥t cá»™ng láº¡i báº±ng 1.\n",
    "\n",
    "**VÃ­ dá»¥**:\n",
    "\n",
    "Giáº£ sá»­ d=2 (vector 2 chiá»u), tá»« trung tÃ¢m $w_c = \\text{\"cat\"}$, tá»« ngá»¯ cáº£nh $w_o = \\text{\"pet\"}$, vÃ  tá»« khÃ´ng liÃªn quan $w_i = \\text{\"table\"}$.\n",
    "\n",
    "$\\mathbf{v}_{\\text{cat}} = [1, 0]$, $\\mathbf{u}_{\\text{pet}} = [0.7, 0.4]$, $\\mathbf{u}_{\\text{table}} = [0.1, -0.5]$.\n",
    "\n",
    "TÃ­ch vÃ´ hÆ°á»›ng:\n",
    "  - $\\mathbf{u}_{\\text{pet}}^\\top \\mathbf{v}_{\\text{cat}} = 0.7 \\cdot 1 + 0.4 \\cdot 0 = 0.7$\n",
    "  - $\\mathbf{u}_{\\text{table}}^\\top \\mathbf{v}_{\\text{cat}} = 0.1 \\cdot 1 + (-0.5) \\cdot 0 = 0.1$\n",
    "\n",
    "HÃ m mÅ©:\n",
    "  - $\\exp(0.7) \\approx 2.0138$\n",
    "  - $\\exp(0.1) \\approx 1.1052$"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2.2. HÃ m há»£p lÃ½ (likelihood)\n",
    "Giáº£ sá»­ ta cÃ³ má»™t chuá»—i vÄƒn báº£n vá»›i Ä‘á»™ dÃ i $T$, trong Ä‘Ã³ tá»« táº¡i vá»‹ trÃ­ $t$ Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  $w^{(t)}$. MÃ´ hÃ¬nh skip-gram giáº£ Ä‘á»‹nh ráº±ng:\n",
    "- CÃ¡c tá»« ngá»¯ cáº£nh trong cá»­a sá»• kÃ­ch thÆ°á»›c $m$ (bao gá»“m $m$ tá»« bÃªn trÃ¡i vÃ  $m$ tá»« bÃªn pháº£i cá»§a tá»« trung tÃ¢m) Ä‘Æ°á»£c sinh ra **Ä‘á»™c láº­p** vá»›i nhau, khi biáº¿t tá»« Ä‘Ã­ch trung tÃ¢m.\n",
    "- HÃ m há»£p lÃ½ (likelihood) cá»§a mÃ´ hÃ¬nh lÃ  xÃ¡c suáº¥t káº¿t há»£p Ä‘á»ƒ sinh ra táº¥t cáº£ cÃ¡c tá»« ngá»¯ cáº£nh cho má»i tá»« trung tÃ¢m trong chuá»—i vÄƒn báº£n.\n",
    "\n",
    "HÃ m há»£p lÃ½ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° sau:\n",
    "\n",
    "$$\n",
    "L = \\prod_{t=1}^{T} \\prod_{-m \\leq j \\leq m,\\ j \\neq 0} P(w^{(t+j)} \\mid w^{(t)}),\n",
    "$$\n",
    "\n",
    "Náº¿u $t+j < 1$ hoáº·c $t+j > T$ (vá»‹ trÃ­ ngoÃ i chuá»—i vÄƒn báº£n), cÃ¡c sá»‘ háº¡ng nÃ y bá»‹ bá» qua. VÃ­ dá»¥, vá»›i $t=1$ vÃ  $m=2$, cÃ¡c vá»‹ trÃ­ $j=-2, -1$ sáº½ khÃ´ng tá»“n táº¡i vÃ  Ä‘Æ°á»£c bá» qua.\n",
    "\n",
    "Ã nghÄ©a cá»§a hÃ m há»£p lÃ½:\n",
    "- HÃ m $L$ biá»ƒu thá»‹ xÃ¡c suáº¥t tá»•ng quÃ¡t Ä‘á»ƒ mÃ´ hÃ¬nh skip-gram sinh ra toÃ n bá»™ cÃ¡c cáº·p tá»« trung tÃ¢m vÃ  tá»« ngá»¯ cáº£nh trong táº­p dá»¯ liá»‡u.\n",
    "- Má»¥c tiÃªu cá»§a MLE lÃ  tÃ¬m cÃ¡c tham sá»‘ ($\\mathbf{v}_i$, $\\mathbf{u}_i$) sao cho $L$ Ä‘áº¡t giÃ¡ trá»‹ lá»›n nháº¥t, tá»©c lÃ  mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n cÃ¡c tá»« ngá»¯ cáº£nh chÃ­nh xÃ¡c nháº¥t cÃ³ thá»ƒ.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2.3. Trainning\n",
    "Má»¥c tiÃªu cá»§a skip-gram lÃ  cá»±c Ä‘áº¡i hÃ³a hÃ m há»£p lÃ½ (Maximum Likelihood Estimation - MLE), tá»©c lÃ  tÃ¬m cÃ¡c vector $\\mathbf{v}_i$ vÃ  $\\mathbf{u}_i$ Ä‘á»ƒ cho $L$ Ä‘áº¡t giÃ¡ trá»‹ lá»›n nháº¥t. Hay mÃ´ hÃ¬nh cÃ³ thá»ƒ dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c cÃ¡c tá»« ngá»¯ cáº£nh dá»±a trÃªn tá»« trung tÃ¢m.\n",
    "\n",
    "Trong thá»±c táº¿, vÃ¬ $L$ lÃ  má»™t tÃ­ch cá»§a nhiá»u xÃ¡c suáº¥t nhá», ta thÆ°á»ng lÃ m viá»‡c vá»›i log-likelihood Ä‘á»ƒ trÃ¡nh váº¥n Ä‘á» sá»‘ há»c (numerical underflow):\n",
    "$$\n",
    "\\log L = \\sum_{t=1}^T \\sum_{-m \\leq j \\leq m, j \\neq 0} \\log P(w^{(t+j)} \\mid w^{(t)}).\n",
    "$$\n",
    "\n",
    "HÃ m máº¥t mÃ¡t Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  phá»§ Ä‘á»‹nh cá»§a log-likelihood:\n",
    "$$\n",
    "J = -\\log L = -\\sum_{t=1}^T \\sum_{-m \\leq j \\leq m, j \\neq 0} \\log P(w^{(t+j)} \\mid w^{(t)}).\n",
    "$$\n",
    "\n",
    "HÃ m máº¥t mÃ¡t nÃ y lÃ  tá»•ng cá»§a logarit xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n trÃªn táº¥t cáº£ cÃ¡c cáº·p tá»« trung tÃ¢m vÃ  tá»« ngá»¯ cáº£nh trong táº­p huáº¥n luyá»‡n. Viá»‡c giáº£m thiá»ƒu hÃ m máº¥t mÃ¡t nÃ y giÃºp mÃ´ hÃ¬nh cáº£i thiá»‡n kháº£ nÄƒng dá»± Ä‘oÃ¡n.\n",
    "\n",
    "Cá»±c Ä‘áº¡i hÃ³a $\\log L$ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i giáº£m thiá»ƒu $J$, Ä‘á»ƒ huáº¥n luyá»‡n, ta sá»­ dá»¥ng [**Stochastic Gradient Descent (SGD)**](https://en.wikipedia.org/wiki/Stochastic_gradient_descent). Trong má»—i vÃ²ng láº·p, ta láº¥y máº«u ngáº«u nhiÃªn má»™t chuá»—i con nhá» hÆ¡n (mini-batch) tá»« táº­p dá»¯ liá»‡u, tÃ­nh toÃ¡n hÃ m máº¥t mÃ¡t cho chuá»—i con Ä‘Ã³, sau Ä‘Ã³ tÃ­nh gradient Ä‘á»ƒ cáº­p nháº­t cÃ¡c tham sá»‘ mÃ´ hÃ¬nh.\n",
    "#### 2.2.3.1. TÃ­nh toÃ¡n gradient: Äiá»ƒm then chá»‘t cá»§a huáº¥n luyá»‡n\n",
    "\n",
    "Äá»ƒ cáº­p nháº­t cÃ¡c vector $\\mathbf{v}_c$ vÃ  $\\mathbf{u}_o$, ta cáº§n tÃ­nh gradient cá»§a hÃ m máº¥t mÃ¡t Ä‘á»‘i vá»›i cÃ¡c tham sá»‘. Äiá»ƒm máº¥u chá»‘t lÃ  tÃ­nh gradient cá»§a logarit xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n $\\log P(w_o \\mid w_c)$, trong Ä‘Ã³ $w_c$ lÃ  tá»« Ä‘Ã­ch trung tÃ¢m vÃ  $w_o$ lÃ  tá»« ngá»¯ cáº£nh.\n",
    "\n",
    "Theo Ä‘á»‹nh nghÄ©a trong mÃ´ hÃ¬nh skip-gram, xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n Ä‘Æ°á»£c tÃ­nh nhÆ° sau:\n",
    "$$\n",
    "P(w_o \\mid w_c) = \\frac{\\exp(\\mathbf{u}_o^\\top \\mathbf{v}_c)}{\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)},\n",
    "$$\n",
    "vÃ  logarit cá»§a nÃ³ lÃ :\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log P(w_o \\mid w_c)\n",
    "&= \\log \\frac{\\exp(\\mathbf{u}_o^\\top \\mathbf{v}_c)}{\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)} \\\\\n",
    "&= \\log \\exp(\\mathbf{u}_o^\\top \\mathbf{v}_c) - \\log\\left(\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)\\right) \\\\\n",
    "&= \\mathbf{u}_o^\\top \\mathbf{v}_c - \\log\\left(\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "#### 2.2.3.2. Chá»©ng minh gradient theo $\\mathbf{v}_c$\n",
    "\n",
    "Ta cáº§n tÃ­nh Ä‘áº¡o hÃ m cá»§a $\\log P(w_o \\mid w_c)$ theo $\\mathbf{v}_c$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\mathbf{v}_c}\\log P(w_o \\mid w_c) \n",
    "&= \\frac{\\partial}{\\partial \\mathbf{v}_c} \\left( \\mathbf{u}_o^\\top \\mathbf{v}_c - \\log\\left(\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)\\right) \\right) \\\\\n",
    "&= \\frac{\\partial}{\\partial \\mathbf{v}_c} \\mathbf{u}_o^\\top \\mathbf{v}_c - \\frac{\\partial}{\\partial \\mathbf{v}_c} \\log\\left(\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)\\right) \\\\ \n",
    "&= \\mathbf{u}_o - \\frac{1}{\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)} \\cdot \\sum_{j \\in \\mathcal{V}} \\exp(\\mathbf{u}_j^\\top \\mathbf{v}_c) \\mathbf{u}_j\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Nháº­n tháº¥y:\n",
    "$$\n",
    "\\frac{\\exp(\\mathbf{u}_j^\\top \\mathbf{v}_c)}{\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)} = P(w_j \\mid w_c),\n",
    "$$\n",
    "nÃªn:\n",
    "$$\n",
    "\\frac{1}{\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)} \\cdot \\sum_{j \\in \\mathcal{V}} \\exp(\\mathbf{u}_j^\\top \\mathbf{v}_c) \\mathbf{u}_j = \\sum_{j \\in \\mathcal{V}} P(w_j \\mid w_c) \\mathbf{u}_j.\n",
    "$$\n",
    "Do Ä‘Ã³, gradient tá»•ng quÃ¡t lÃ :\n",
    "$$\n",
    "\\frac{\\partial \\log P(w_o \\mid w_c)}{\\partial \\mathbf{v}_c} = \\mathbf{u}_o - \\sum_{j \\in \\mathcal{V}} P(w_j \\mid w_c) \\mathbf{u}_j.\n",
    "$$\n",
    "**Ã nghÄ©a**: Gradient nÃ y bao gá»“m hai pháº§n:\n",
    "- $\\mathbf{u}_o$: Vector tá»« ngá»¯ cáº£nh thá»±c táº¿, Ä‘áº¡i diá»‡n cho tá»« $w_o$ mÃ  mÃ´ hÃ¬nh cáº§n dá»± Ä‘oÃ¡n.\n",
    "- $\\sum_{j \\in \\mathcal{V}} P(w_j \\mid w_c) \\mathbf{u}_j$: Ká»³ vá»ng cá»§a vector tá»« ngá»¯ cáº£nh trÃªn toÃ n bá»™ tá»« Ä‘iá»ƒn, dá»±a trÃªn xÃ¡c suáº¥t dá»± Ä‘oÃ¡n.\n",
    "\n",
    "Gradient nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ cáº­p nháº­t $\\mathbf{v}_c$ trong SGD theo cÃ´ng thá»©c:\n",
    "$$\n",
    "\\mathbf{v}_c \\leftarrow \\mathbf{v}_c + \\eta \\left( \\mathbf{u}_o - \\sum_{j \\in \\mathcal{V}} P(w_j \\mid w_c) \\mathbf{u}_j \\right),\n",
    "$$\n",
    "vá»›i $\\eta$ lÃ  tá»‘c Ä‘á»™ há»c (learning rate).\n",
    "#### 2.2.3.3. Káº¿t quáº£ sau huáº¥n luyá»‡n\n",
    "\n",
    "Sau khi huáº¥n luyá»‡n, vá»›i má»—i tá»« $w_i$ trong tá»« Ä‘iá»ƒn (cÃ³ chá»‰ sá»‘ $i$), ta thu Ä‘Æ°á»£c hai vector:\n",
    "\n",
    "- $\\mathbf{v}_i$: Vector tá»« Ä‘Ã­ch trung tÃ¢m.\n",
    "- $\\mathbf{u}_i$: Vector tá»« ngá»¯ cáº£nh.\n",
    "\n",
    "Trong cÃ¡c á»©ng dá»¥ng NLP (nhÆ° phÃ¢n loáº¡i vÄƒn báº£n, phÃ¢n tÃ­ch cáº£m xÃºc), **vector tá»« Ä‘Ã­ch trung tÃ¢m $\\mathbf{v}_i$** thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m biá»ƒu diá»…n chÃ­nh cho tá»« $w_i$, vÃ¬ nÃ³ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘á»ƒ dá»± Ä‘oÃ¡n ngá»¯ cáº£nh xung quanh."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. BÃ i táº­p"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## CÃ¢u 1:\n",
    "Äá»™ phá»©c táº¡p tÃ­nh toÃ¡n cá»§a má»—i gradient lÃ  bao nhiÃªu? Náº¿u tá»« Ä‘iá»ƒn chá»©a má»™t lÆ°á»£ng lá»›n cÃ¡c tá»«, Ä‘iá»u nÃ y sáº½ gÃ¢y ra váº¥n Ä‘á» gÃ¬?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.1. Äá»™ phá»©c táº¡p tÃ­nh toÃ¡n cá»§a má»—i gradient\n",
    "\n",
    "Nháº¯c láº¡i cÃ´ng thá»©c tÃ­nh gradient cá»§a hÃ m máº¥t mÃ¡t theo $\\mathbf{v}_c$ trong mÃ´ hÃ¬nh Skip-gram (15.1.8):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\textrm{log}\\, P(w_o \\mid w_c)}{\\partial \\mathbf{v}_c} = \\mathbf{u}_o - \\sum_{j \\in \\mathcal{V}} P(w_j \\mid w_c) \\mathbf{u}_j\n",
    "$$\n",
    "\n",
    "Nháº¯c láº¡i cÃ´ng thá»©c tÃ­nh gradient cá»§a hÃ m máº¥t mÃ¡t theo $\\mathbf{v}_{o_i}$ trong mÃ´ hÃ¬nh CBOW (15.1.15):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log\\, P(w_c \\mid \\mathcal{W}_o)}{\\partial \\mathbf{v}_{o_i}} = \\frac{1}{2m}\\left(\\mathbf{u}_c - \\sum_{j \\in \\mathcal{V}} P(w_j \\mid \\mathcal{W}_o) \\mathbf{u}_j \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "- Dá»… tháº¥y, Ä‘á»‘i vá»›i cáº£ 2 mÃ´ hÃ¬nh, Ä‘á»ƒ tÃ­nh Ä‘Æ°á»£c gradient ta pháº£i tÃ­nh xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n cho má»i tá»« $w_j$ cÃ³ trong tá»« Ä‘iá»ƒn $\\mathcal{V}$ vá»›i má»™t tá»« cho trÆ°á»›c.\n",
    "- Do Ä‘Ã³, Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n cá»§a má»—i gradient trong cáº£ 2 mÃ´ hÃ¬nh Ä‘á»u lÃ  $O(|\\mathcal{V}| \\cdot d)$, vá»›i $d$ lÃ  sá»‘ chiá»u cá»§a vector embedding vÃ  $\\mathcal{V}$ lÃ  tá»« Ä‘iá»ƒn\n",
    "\n",
    "\n",
    "### 1.2. Váº¥n Ä‘á» khi tá»« Ä‘iá»ƒn chá»©a má»™t lÆ°á»£ng lá»›n cÃ¡c tá»«\n",
    "\n",
    "- Tá»« Ä‘á»™ phá»©c táº¡p trÃªn ta tháº¥y, má»—i láº§n huáº¥n luyá»‡n cho má»™t cáº·p tá»«, ta Ä‘á»u pháº£i tÃ­nh xÃ¡c suáº¥t cho táº¥t cáº£ cÃ¡c tá»« trong tá»« Ä‘iá»ƒn\n",
    "- Äiá»u nÃ y ráº¥t tá»‘n thá»i gian, dáº«n Ä‘áº¿n huáº¥n luyá»‡n ráº¥t cháº­m há»™i tá»¥, khÃ´ng kháº£ thi vá»›i dá»¯ liá»‡u thá»±c táº¿.\n",
    "\n",
    "**Giáº£i phÃ¡p:** DÃ¹ng ká»¹ thuáº­t Negative Sampling (xem má»¥c 15.2.1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ã tÆ°á»Ÿng: Nháº­n diá»‡n vÃ  táº¡o cá»¥m tá»« (phrases) trÆ°á»›c khi huáº¥n luyá»‡n Word2Vec\n",
    "\n",
    "TrÆ°á»›c khi huáº¥n luyá»‡n Word2Vec, ta xÃ¡c Ä‘á»‹nh ra cÃ¡c cá»¥m tá»« phá»• biáº¿n trong má»™t ngá»¯ cáº£nh nhÆ°ng Ã­t phá»• biáº¿n trong cÃ¡c ngá»¯ cáº£nh khÃ¡c, nhÆ°: `\"new york\"`, `\"san francisco\"`... (trong khi cá»¥m `\"this is\"` thÃ¬ xuáº¥t hiá»‡n trong ráº¥t nhiá»u ngá»¯ cáº£nh), sau Ä‘Ã³ ná»‘i chÃºng láº¡i vÃ  coi chÃºng lÃ  má»™t tá»« riÃªng trong tá»« Ä‘iá»ƒn khi huáº¥n luyá»‡n embedding.\n",
    "\n",
    "---\n",
    "\n",
    "## PhÆ°Æ¡ng phÃ¡p phÃ¡t hiá»‡n cá»¥m tá»«: Dá»±a trÃªn thá»‘ng kÃª Ä‘á»“ng xuáº¥t hiá»‡n\n",
    "CÃ³ nhiá»u phÆ°Æ¡ng phÃ¡p phÃ¡t hiá»‡n cá»¥m tá»« Ä‘Ã£ Ä‘Æ°á»£c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã³, nhÆ°ng chÃºng khÃ´ng náº±m trong pháº¡m vi nghiÃªn cá»©u cá»§a bÃ i bÃ¡o nÃªn nhÃ³m tÃ¡c giáº£ chá»‰ sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n vÃ  Ä‘á»§ hiá»‡u quáº£.\n",
    "\n",
    "Ta kiá»ƒm tra xem cáº·p tá»« $w_i, w_j$ cÃ³ nÃªn Ä‘Æ°á»£c ná»‘i thÃ nh má»™t cá»¥m hay khÃ´ng báº±ng cÃ´ng thá»©c sau:\n",
    "\n",
    "$$\n",
    "\\text{score}(w_i, w_j) = \\frac{C(w_i w_j) - \\delta}{C(w_i) \\cdot C(w_j)}\n",
    "$$\n",
    "\n",
    "Trong Ä‘Ã³:\n",
    "- $C(w_i)$, $C(w_j)$: táº§n suáº¥t cá»§a tá»«ng tá»« riÃªng láº»,\n",
    "- $C(w_i w_j)$: táº§n suáº¥t cá»§a cá»¥m 2 tá»« xuáº¥t hiá»‡n liÃªn tiáº¿p,\n",
    "- $\\delta$: má»™t háº±ng sá»‘ Ä‘á»ƒ trÃ¡nh ná»‘i nhá»¯ng cá»¥m cÃ³ táº§n suáº¥t tháº¥p (thÆ°á»ng lÃ  5).\n",
    "\n",
    "Äá»“ng thá»i Ä‘áº·t ra má»™t ngÆ°á»¡ng cá»‘ Ä‘á»‹nh. Náº¿u score vÆ°á»£t ngÆ°á»¡ng nÃ y, ta xem $w_i w_j$ lÃ  cá»¥m cá»‘ Ä‘á»‹nh.\n",
    "\n",
    "> **VÃ­ dá»¥ 1**:  \n",
    "> Náº¿u `\"new\"` xuáº¥t hiá»‡n 5000 láº§n, `\"york\"` 3000 láº§n, `\"new york\"` xuáº¥t hiá»‡n 2800 láº§n, thÃ¬:\n",
    ">\n",
    "> $\\text{score}(\\text{\"new\"}, \\text{\"york\"}) = \\frac{2800 - 5}{5000 \\cdot 3000} \\approx 0.000186$\n",
    "> \n",
    "> Náº¿u ngÆ°á»¡ng lÃ  0.0001 â†’ `\"new york\"` Ä‘Æ°á»£c giá»¯ láº¡i thÃ nh `\"new_york\"`.\n",
    "\n",
    "> **VÃ­ dá»¥ 2**:  \n",
    "> Náº¿u `\"this\"` xuáº¥t hiá»‡n 10000 láº§n, `\"is\"` 9500 láº§n, `\"this is\"` xuáº¥t hiá»‡n 5000 láº§n, thÃ¬:\n",
    ">\n",
    "> $\\text{score}(\\text{\"this\"}, \\text{\"is\"}) = \\frac{5000 - 5}{10000 \\cdot 9500} \\approx 0.0000525789474$\n",
    "> \n",
    "> Náº¿u ngÆ°á»¡ng lÃ  0.0001 â†’ `\"this is\"` khÃ´ng Ä‘Æ°á»£c ná»‘i láº¡i thÃ nh cá»¥m tá»«"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.1. Má»‘i quan há»‡ giá»¯a tÃ­ch vÃ´ hÆ°á»›ng cá»§a hai vector tá»« vÃ  Ä‘á»™ tÆ°Æ¡ng tá»± cÃ´-sin\n",
    "\n",
    "Nháº¯c láº¡i cÃ´ng thá»©c tÃ­nh vÃ´ hÆ°á»›ng trong trÆ°á»ng há»£p 2 vector tá»«:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{u}_{w_o}^\\top \\boldsymbol{v}_{w_c} = \\|\\boldsymbol{u}_{w_o}\\| \\cdot \\|\\boldsymbol{v}_{w_c}\\| \\cdot \\cos(\\theta)\n",
    "$$\n",
    "\n",
    "Trong Ä‘Ã³:\n",
    "- $\\theta$: gÃ³c giá»¯a hai vector.\n",
    "- $\\cos(\\theta)$: **Ä‘á»™ tÆ°Æ¡ng tá»± cosine** giá»¯a hai vector, cÃ³ miá»n giÃ¡ trá»‹ tá»« -1 (khi 2 vector ngÆ°á»£c hÆ°á»›ng) Ä‘áº¿n 1 (khi 2 vector cÃ¹ng hÆ°á»›ng) vÃ  báº±ng 0 khi 2 vector vuÃ´ng gÃ³c\n",
    "\n",
    "ğŸ‘‰ **TÃ­ch vÃ´ hÆ°á»›ng cÃ ng lá»›n (theo chiá»u dÆ°Æ¡ng)**, nghÄ©a lÃ :\n",
    "- Hai vector cÃ ng **cÃ¹ng hÆ°á»›ng** (cosine gáº§n 1),\n",
    "- Hoáº·c cÃ³ **Ä‘á»™ dÃ i lá»›n** (cÅ©ng áº£nh hÆ°á»Ÿng, nhÆ°ng khÃ´ng mang nghÄ©a ngá»¯ nghÄ©a nhiá»u báº±ng gÃ³c).\n",
    "\n",
    "\n",
    "\n",
    "### 3.2. VÃ¬ sao cÃ¡c tá»« cÃ³ nghÄ©a gáº§n nhau thÆ°á»ng cÃ³ Ä‘á»™ tÆ°Æ¡ng tá»± cosine cao?\n",
    "\n",
    "\n",
    "Nháº¯c láº¡i cÃ´ng thá»©c cá»§a Skip-gram: Vá»›i cáº·p tá»« $(w_c, w_o)$, ta tá»‘i Ä‘a hÃ³a xÃ¡c suáº¥t sau:\n",
    "\n",
    "$$\n",
    "P(w_o | w_c) = \\frac{\\exp(\\boldsymbol{u}_{w_o}^\\top \\boldsymbol{v}_{w_c})}{\\sum_{w \\in V} \\exp(\\boldsymbol{u}_w^\\top \\boldsymbol{v}_{w_c})}\n",
    "$$\n",
    "\n",
    "Quan sÃ¡t cÃ´ng thá»©c nÃ y ta tháº¥y: Náº¿u hai tá»« hay cÃ¹ng xuáº¥t hiá»‡n, tá»©c lÃ  xÃ¡c suáº¥t $P$ á»Ÿ trÃªn lá»›n, thÃ¬ tÃ­ch vÃ´ hÆ°á»›ng $\\boldsymbol{u}_{w_o}^\\top \\boldsymbol{v}_{w_c}$ cÅ©ng lá»›n.\n",
    "\n",
    "Máº·t khÃ¡c, ta huáº¥n luyá»‡n Skip-gram báº±ng cÃ¡ch cá»±c Ä‘áº¡i hoÃ¡ há»£p lÃ½ xÃ¡c suáº¥t $P$ Ä‘Ã³. Do váº­y, mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n sao cho lÃ m tÄƒng tÃ­ch vÃ´ hÆ°á»›ng cá»§a 2 vector tá»« tÆ°Æ¡ng tá»± nhau, tá»« Ä‘Ã³ lÃ m tÄƒng Ä‘á»™ tÆ°Æ¡ng tá»± cosine.\n",
    "\n",
    "\n",
    "**TÃ³m láº¡i:**\n",
    "- Trong mÃ´ hÃ¬nh Skip-Gram cá»§a Word2Vec, xÃ¡c suáº¥t dá»± Ä‘oÃ¡n tá»« phá»¥ thuá»™c vÃ o tÃ­ch vÃ´ hÆ°á»›ng giá»¯a hai vector tá»«, mÃ  tÃ­ch vÃ´ hÆ°á»›ng láº¡i phá»¥ thuá»™c trá»±c tiáº¿p vÃ o Ä‘á»™ tÆ°Æ¡ng tá»± cosine.\n",
    "- Khi cÃ¡c tá»« cÃ³ nghÄ©a gáº§n nhau, chÃºng thÆ°á»ng xuáº¥t hiá»‡n trong nhá»¯ng ngá»¯ cáº£nh giá»‘ng nhau, khiáº¿n cÃ¡c vector cá»§a chÃºng hÆ°á»›ng gáº§n nhau trong khÃ´ng gian â†’ Ä‘á»™ tÆ°Æ¡ng tá»± cosine cao."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  }
 ]
}
